{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text classification with pretrained BERT model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"C54qnprAdFhY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594165971608,"user_tz":240,"elapsed":3361,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"cb34af0b-1b78-4368-e39c-dd6d9cbadeab"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p7CgOS3PdzMz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594165971610,"user_tz":240,"elapsed":3347,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"6a2840bf-2d8a-40d5-88d8-e18c3613df54"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BCM3JjuLd5mZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"ok","timestamp":1594165974316,"user_tz":240,"elapsed":6037,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"02bc46a6-44fe-4345-f57c-b3bff91ff463"},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n","Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DfvwgKL7WE2T","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"75_ymzIFdQPh","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1594166084777,"user_tz":240,"elapsed":116484,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"a579ceb1-d40f-4010-a252-8a05015cafa8"},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-3f488a59-875c-41c5-8805-e85444778efc\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-3f488a59-875c-41c5-8805-e85444778efc\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving labeled_data.csv to labeled_data (3).csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5hS3cw_md4fL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1594166084778,"user_tz":240,"elapsed":116472,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"4ea5cc3e-9571-4cc4-f495-6767f74cc0fb"},"source":["import io\n","import pandas as pd\n","import numpy as np\n","\n","df = pd.read_csv(io.BytesIO(uploaded['labeled_data.csv']))\n","df.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>tag</th>\n","      <th>starter_content</th>\n","      <th>category</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Public calendar for SmartThings developer events</td>\n","      <td>Groups &amp; Events</td>\n","      <td>dear community in 2015 we are going to do a be...</td>\n","      <td>General Discussion</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>[RELEASE] Universal Ecobee Suite, Version 1.8.01</td>\n","      <td>Community Created SmartApps</td>\n","      <td>1460×174 413 kb important warning about ecobee...</td>\n","      <td>SmartApps &amp; Automations</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>[BETA] Hue Dimmer Switch DTH (No Hue bridge) r...</td>\n","      <td>Community Created Device Types</td>\n","      <td>i’ve rewritten hue dimmer switch dth no hue br...</td>\n","      <td>Devices &amp; Integrations</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>[RELEASE] ST_Anything - Arduino/ESP8266/ESP32</td>\n","      <td>Projects &amp; Stories</td>\n","      <td>stanything allows you to integrate a custom ar...</td>\n","      <td>Wiki</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>New V3 app: notify if front door is open more ...</td>\n","      <td>Automation Ideas</td>\n","      <td>i’m trying to setup a simple automation at my ...</td>\n","      <td>SmartApps &amp; Automations</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  id  ...                 category label\n","0           0   0  ...       General Discussion     6\n","1           1   1  ...  SmartApps & Automations     4\n","2           2   2  ...   Devices & Integrations     2\n","3           3   3  ...                     Wiki     1\n","4           4   4  ...  SmartApps & Automations     4\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"CPgWu3wgHDbw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1594166084780,"user_tz":240,"elapsed":116459,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"bbadce47-f489-4959-9577-3a5a3708e6ce"},"source":["from collections import Counter\n","\n","tagMap = Counter(df.category)\n","for k, v in tagMap.items():\n","  if v > 1:\n","    print(\"Tag: {}, frequency: {}\".format(k, v))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Tag: General Discussion, frequency: 473\n","Tag: SmartApps & Automations, frequency: 719\n","Tag: Devices & Integrations, frequency: 3132\n","Tag: Wiki, frequency: 309\n","Tag: Announcements, frequency: 21\n","Tag: Apps & Clients, frequency: 322\n","Tag: Meta, frequency: 14\n","Tag: Developer Programs, frequency: 10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cElJyGXZKEOw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594166084781,"user_tz":240,"elapsed":116447,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"1256de0c-6d7c-403b-8670-fef2fec39d03"},"source":["df = df.dropna(axis=0)\n","len(df)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5000"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"BYmkGgn3sj20","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594166085382,"user_tz":240,"elapsed":117035,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"276953af-9d5d-411f-894d-106e36910e9f"},"source":["import os\n","from datetime import datetime\n","import matplotlib.pyplot as plt   #Data visualisation libraries\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1666, random_state=0)\n","\n","for train_index, test_index in sss.split(df.starter_content, df.label):\n","    train_dev = df.iloc[train_index]\n","    test = df.iloc[test_index]\n","\n","sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n","for train_index, dev_index in sss.split(train_dev.starter_content, train_dev.label):\n","    train = df.iloc[train_index]\n","    dev = df.iloc[dev_index]\n","    \n","train.shape, dev.shape, test.shape"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((3333, 7), (834, 7), (833, 7))"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"TJr9B5cbd3rD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594166086296,"user_tz":240,"elapsed":117936,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","# Tokenize all of the sentences and map the tokens to their word IDs.\n","max_len = 256\n","def tokenize_text(text, max_len):\n","  input_ids = []\n","  for sent in text:\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    encoded_sent = tokenizer.encode(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        padding = 'max_length',\n","\n","                        # This function also supports truncation and conversion\n","                        # to pytorch tensors, but we need to do padding, so we\n","                        # can't use these features :( .\n","                        max_length = max_len,\n","                        truncation = True          # Truncate all sentences.\n","                        #return_tensors = 'pt',     # Return pytorch tensors.\n","                  )\n","    \n","    # Add the encoded sentence to the list.\n","    input_ids.append(encoded_sent)\n","  return input_ids"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"-5TZTrzBhSan","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594166109877,"user_tz":240,"elapsed":141507,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["input_ids = np.array(tokenize_text(train_dev.starter_content, max_len))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHGnbm49s2rY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":428},"executionInfo":{"status":"ok","timestamp":1594166109879,"user_tz":240,"elapsed":141495,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"b607672d-1d14-4ef4-9612-f2a27600372f"},"source":["# Print sentence 0, now as a list of IDs.\n","print('Original: ', train_dev.starter_content[0])\n","print('Token IDs:', input_ids[0])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Original:  dear community in 2015 we are going to do a better job of event planning if you want to keep up with which events are sponsoring and participating in add this google calendar to your account google calendar please reply to this thread with suggestions for events you want us to participate in also we are building out an ambassador program that lets you represent us at hackathons meetups and other developer eventstgauchat http://devguild.heavybit.com/greg https://www.google.com/calendar/ical/physicalgraph.com_i84rmh4o3ca9a8sjr3skq86v4o%40group.calendar.google.com/public/basic.icsyep we want to make it a big event\n","Token IDs: [  101  1045  1521  1049  2559  2005  2188  8346  3688  2005  1996 12419\n","  1037  4121  3291  2057  2031  7336  5610 29034 25422  2015  1998 11640\n","  2296 12419  2711  2038  2023  2342  2026  6047 20744  2015  8934  2003\n","  2006  1996  2126  2009  3504  2066  1037 10392  4132  1999  2026  3988\n"," 17193  1045  2031  2464  2070  2477  2008  2453  2022  6179  2021  1045\n","  2031  2025  8061  2009  2091  2664  2005  9499  2075  5733  2057  2342\n","  1037  4408  2358  3217  4783  2673  3849  2000 17902 20675  1516  2025\n","  2734  1037  2235  2419  2422  8569 20850  2008  2071  2022  5614  1999\n","  2235 17407  1998  2872  2105  1996  2160  2052  3710  1996  3800  2178\n","  9499  2075  5080  2003  1037  2793  6073  2099  2023  2003  2074  1037\n","  2260  1058  2544  1997  1996 24987  2518  1999  6047 11640  2017  2064\n","  4965  2260  5285  2102  2793  6073  2869  2008 13354  2378  2007 12639\n"," 19400  2015  2035  2008  2003  2734  2003  2019 13307  2008 13354  2015\n","  2046  1996  2813 19706  2007  6047  4933  1998  3640  1037  2260  5285\n","  2102 13330  6434  1045  4033  1521  1056  2464  2122  2800  2005 13907\n","  2242  2008 11487  2015  2614  2066  1996  3042 13060  2052  2022  6179\n","  1037 29089 25422  6942  2008  2071  9495  1996  5956  2545  2052  2022\n","  6179  1045  2031  2464  1996  1062 25855  3489  5610 29034  2216  2298\n","  3819  2064  3087  2391  2033  1999  1996  2157  3257  2030  3749  2070\n","  3176  2592  4283  6287 12155  2860  4283  2005  2035  1996 18558  1045\n","  2031  1037  2843  1997  2477  2000  2298  1999  2000  1045  5993  2008\n"," 12530  8010  2003   102]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mwJ2jvy6VqbY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594166109880,"user_tz":240,"elapsed":141486,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"a78c5ecf-4d07-422c-a456-ea12d0d41105"},"source":["print('Max sentence length: ', min([len(sen) for sen in input_ids]))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Max sentence length:  256\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lX6PenE5yggI","colab_type":"text"},"source":["### **Attention Masks**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8d6B4cj7vk9W","colab":{},"executionInfo":{"status":"ok","timestamp":1594166110140,"user_tz":240,"elapsed":141736,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["# Create attention masks\n","attention_masks = []\n","\n","# For each sentence...\n","for sent in input_ids:\n","    \n","    # Create the attention mask.\n","    #   - If a token ID is 0, then it's padding, set the mask to 0.\n","    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n","    att_mask = [int(token_id > 0) for token_id in sent]\n","    \n","    # Store the attention mask for this sentence.\n","    attention_masks.append(att_mask)\n","\n","attention_masks = np.array(attention_masks)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"avahvs2zyc8v","colab_type":"text"},"source":["### **Training & Validation Split**"]},{"cell_type":"code","metadata":{"id":"YOvBaSmwjhZ3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594166110142,"user_tz":240,"elapsed":141723,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["for train_index, test_index in sss.split(input_ids, train_dev.label):\n","    train_inputs = input_ids[train_index]\n","    train_labels = np.array(train_dev.label.iloc[train_index].astype(int))\n","    validation_inputs = input_ids[test_index]\n","    validation_labels = np.array(train_dev.label.iloc[test_index].astype(int))\n","\n","for train_index, test_index in sss.split(attention_masks, train_dev.label):\n","    train_masks = attention_masks[train_index]\n","    validation_masks = attention_masks[test_index]\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"WTMqvL1Lq078","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1594166110143,"user_tz":240,"elapsed":141715,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"6402504b-7af6-4718-eb5e-5115acc1feca"},"source":["type(train_inputs), type(validation_inputs), type(train_labels), type(validation_labels), type(train_masks), type(validation_masks)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(numpy.ndarray,\n"," numpy.ndarray,\n"," numpy.ndarray,\n"," numpy.ndarray,\n"," numpy.ndarray,\n"," numpy.ndarray)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"9a9vUbx1yOO4","colab_type":"text"},"source":["### **Converting to PyTorch Data Types**"]},{"cell_type":"code","metadata":{"id":"5brYKYhwhdPV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594166110144,"user_tz":240,"elapsed":141708,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["# Convert all inputs and labels into torch tensors, the required datatype \n","# for our model.\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIWzFtzMi5si","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594166110145,"user_tz":240,"elapsed":141700,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here.\n","# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n","# 16 or 32.\n","\n","batch_size = 16\n","\n","# Create the DataLoader for our training set.\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set.\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yfbul542yJKi","colab_type":"text"},"source":["### **BertForSequenceClassification**"]},{"cell_type":"code","metadata":{"id":"nufMxRE1i6bt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594166119543,"user_tz":240,"elapsed":151089,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"1465a6d8-c2cc-49fa-fccd-23abcfb88f1f"},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = len(df.label.unique()), # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"_yxRLruCrIFE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":612},"executionInfo":{"status":"ok","timestamp":1594166119544,"user_tz":240,"elapsed":151082,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"b9203935-c968-4fc8-8a09-09256b6a9395"},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (8, 768)\n","classifier.bias                                                 (8,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dPQJIZd1x_k7","colab_type":"text"},"source":["### **Optimizer & Learning Rate Scheduler**"]},{"cell_type":"code","metadata":{"id":"WLruA08mrMLg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594166119545,"user_tz":240,"elapsed":151074,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"UC3TigS9rP3g","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594166119548,"user_tz":240,"elapsed":151065,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 4\n","\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h2vbGjxAx1_p","colab_type":"text"},"source":["### **Training Loop**"]},{"cell_type":"code","metadata":{"id":"8j2FRKvurTp-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594166119549,"user_tz":240,"elapsed":151057,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"zsV96cZQrXbC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594166119550,"user_tz":240,"elapsed":151050,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"B5NjrdqIrato","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594166801151,"user_tz":240,"elapsed":832642,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"f1a6753e-c70c-49e7-bb81-2602a848a9ef"},"source":["import random\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # This will return the loss (rather than the model output) because we\n","        # have provided the `labels`.\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        outputs = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels)\n","        \n","        # The call to `model` always returns a tuple, so we need to pull the loss value out of the tuple.\n","        loss = outputs[0]\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","    \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # Telling the model not to compute or store gradients, saving memory and\n","        # speeding up validation\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # This will return the logits rather than the loss because we have\n","            # not provided labels.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # Get the \"logits\" output by the model. The \"logits\" are the output\n","        # values prior to applying an activation function like the softmax.\n","        logits = outputs[0]\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # Calculate the accuracy for this batch of test sentences.\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        \n","        # Accumulate the total accuracy.\n","        eval_accuracy += tmp_eval_accuracy\n","\n","        # Track the number of batches\n","        nb_eval_steps += 1\n","\n","    # Report the final accuracy for this validation run.\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of    209.    Elapsed: 0:00:29.\n","  Batch    80  of    209.    Elapsed: 0:01:00.\n","  Batch   120  of    209.    Elapsed: 0:01:30.\n","  Batch   160  of    209.    Elapsed: 0:02:00.\n","  Batch   200  of    209.    Elapsed: 0:02:31.\n","\n","  Average training loss: 1.15\n","  Training epcoh took: 0:02:37\n","\n","Running Validation...\n","  Accuracy: 0.68\n","  Validation took: 0:00:14\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of    209.    Elapsed: 0:00:30.\n","  Batch    80  of    209.    Elapsed: 0:01:00.\n","  Batch   120  of    209.    Elapsed: 0:01:30.\n","  Batch   160  of    209.    Elapsed: 0:02:00.\n","  Batch   200  of    209.    Elapsed: 0:02:30.\n","\n","  Average training loss: 0.86\n","  Training epcoh took: 0:02:37\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation took: 0:00:14\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of    209.    Elapsed: 0:00:30.\n","  Batch    80  of    209.    Elapsed: 0:01:00.\n","  Batch   120  of    209.    Elapsed: 0:01:30.\n","  Batch   160  of    209.    Elapsed: 0:02:01.\n","  Batch   200  of    209.    Elapsed: 0:02:31.\n","\n","  Average training loss: 0.67\n","  Training epcoh took: 0:02:37\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation took: 0:00:14\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of    209.    Elapsed: 0:00:30.\n","  Batch    80  of    209.    Elapsed: 0:01:00.\n","  Batch   120  of    209.    Elapsed: 0:01:30.\n","  Batch   160  of    209.    Elapsed: 0:02:00.\n","  Batch   200  of    209.    Elapsed: 0:02:30.\n","\n","  Average training loss: 0.54\n","  Training epcoh took: 0:02:37\n","\n","Running Validation...\n","  Accuracy: 0.70\n","  Validation took: 0:00:14\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0Ft3ZC6VrdRh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":461},"executionInfo":{"status":"ok","timestamp":1594166801618,"user_tz":240,"elapsed":833100,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"6b999a22-0c7c-42b6-9320-67dd624b91d0"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(loss_values, 'b-o')\n","\n","# Label the plot.\n","plt.title(\"Training loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","\n","plt.show()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Ynt5vO9Kwico","colab_type":"text"},"source":["### **Performance on Test set**"]},{"cell_type":"code","metadata":{"id":"4fpq-QQwwTwT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594166806013,"user_tz":240,"elapsed":837487,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["input_ids = np.array(tokenize_text(test.starter_content, max_len))"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"pkZla_OfjsUE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594166806014,"user_tz":240,"elapsed":837479,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"77c12ce4-bf7f-4ece-faf9-f75754f66f26"},"source":["print('Min sentence length: ', min([len(sen) for sen in input_ids]))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Min sentence length:  256\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jcuX288akS0m","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594166806015,"user_tz":240,"elapsed":837470,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["labels = np.array(test.label)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"HgiFK5xNj9Wn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594166806016,"user_tz":240,"elapsed":837460,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"d854e891-4f37-4dfb-f739-fbbabe3a042f"},"source":["print('Min sentence length: ', min([len(sen) for sen in input_ids]))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Min sentence length:  256\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zk_9YH8Iwf25","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594166806018,"user_tz":240,"elapsed":837453,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}}},"source":["attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask) \n","\n","# Convert to tensors.\n","prediction_inputs = torch.tensor(input_ids)\n","prediction_masks = torch.tensor(attention_masks)\n","prediction_labels = torch.tensor(labels)\n","\n","# Set the batch size.  \n","batch_size = 16\n","\n","# Create the DataLoader.\n","prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7BEcahTAw96j","colab_type":"text"},"source":["### **Evaluation on Test set**"]},{"cell_type":"code","metadata":{"id":"ZxgI2mXBw9HL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594166819541,"user_tz":240,"elapsed":850968,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"d19ca30d-da80-4631-bd64-276eca0b920e"},"source":["# Prediction on test set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  logits = outputs[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","print('    DONE.')"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Predicting labels for 833 test sentences...\n","    DONE.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MbGNBbATxKc4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1594166819542,"user_tz":240,"elapsed":850960,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"c8f0d956-fae9-4d2b-e4a4-25c871ab0c5f"},"source":["from sklearn.metrics import matthews_corrcoef\n","\n","matthews_set = []\n","\n","# Evaluate each test batch using Matthew's correlation coefficient\n","print('Calculating Matthews Corr. Coef. for each batch...')\n","\n","# For each input batch...\n","for i in range(len(true_labels)):\n","  \n","  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n","  # and one column for \"1\"). Pick the label with the highest value and turn this\n","  # in to a list of 0s and 1s.\n","  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","  \n","  # Calculate and store the coef for this batch.  \n","  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n","  matthews_set.append(matthews)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Calculating Matthews Corr. Coef. for each batch...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n","  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"nM1G4OiQxOcg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594166819546,"user_tz":240,"elapsed":850955,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"0b0ff379-3a02-41ce-c0d4-68522ebd0b5b"},"source":["# Combine the predictions for each batch into a single list of 0s and 1s.\n","flat_predictions = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = [item for sublist in true_labels for item in sublist]\n","\n","# Calculate the MCC\n","mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","\n","print('MCC: %.3f' % mcc)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["MCC: 0.446\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9XOJlsTExT5K","colab_type":"text"},"source":["### **Saving & Loading fine-tuned model**"]},{"cell_type":"code","metadata":{"id":"bKiQ1LRoxcl7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1594166820655,"user_tz":240,"elapsed":852056,"user":{"displayName":"Akim Borbuev","photoUrl":"","userId":"04341418346598593873"}},"outputId":"6d52db21-96fa-40ca-9ef2-1e58b7fbaf20"},"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = './model_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Saving model to ./model_save/\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('./model_save/vocab.txt',\n"," './model_save/special_tokens_map.json',\n"," './model_save/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":34}]}]}